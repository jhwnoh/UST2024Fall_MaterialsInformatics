{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhwnoh/UST2024Fall_MaterialsInformatics/blob/main/Week10_Excercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESOtBEsDrQe_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRZq6bKTrVs2"
      },
      "outputs": [],
      "source": [
        "TorchModule = {'linear':nn.Linear,\n",
        "               'conv1d':nn.Conv1d,\n",
        "               'conv2d':nn.Conv2d,\n",
        "               'conv3d':nn.Conv3d,\n",
        "               'convtrans1d':nn.ConvTranspose1d,\n",
        "               'convtrans2d':nn.ConvTranspose2d,\n",
        "               'convtrans3d':nn.ConvTranspose3d,\n",
        "               'maxpool1d':nn.MaxPool1d,\n",
        "               'maxpool2d':nn.MaxPool2d,\n",
        "               'maxpool3d':nn.MaxPool3d,\n",
        "               'sigmoid':nn.Sigmoid(),\n",
        "               'tanh':nn.Tanh(),\n",
        "               'relu':nn.ReLU(),\n",
        "               'lrelu':nn.LeakyReLU(),\n",
        "               'bn1d':nn.BatchNorm1d,\n",
        "               'bn2d':nn.BatchNorm2d,\n",
        "               'bn3d':nn.BatchNorm3d,\n",
        "               'dropout':nn.Dropout}\n",
        "\n",
        "def LayerGroup(mylayers):\n",
        "    mylayer_list = mylayers.split(';')\n",
        "\n",
        "    module_list = []\n",
        "    for mylayer in mylayer_list:\n",
        "        if '-' in mylayer:\n",
        "            tmp = mylayer.split('-')\n",
        "\n",
        "            name = tmp[0]\n",
        "\n",
        "            if name == 'linear':\n",
        "                dims = [int(v) for v in tmp[1].split(',')]\n",
        "                sub_model = TorchModule[name](*dims)\n",
        "            elif 'conv' in name:\n",
        "                dims = [int(v) for v in tmp[1].split(',')]\n",
        "                sub_model = TorchModule[name](*dims)\n",
        "            elif 'pool' in name:\n",
        "                dims = [int(v) for v in tmp[1].split(',')]\n",
        "                sub_model = TorchModule[name](*dims)\n",
        "            elif 'bn' in name:\n",
        "                dims = [int(v) for v in tmp[1].split(',')]\n",
        "                sub_model = TorchModule[name](*dims)\n",
        "            elif name == 'dropout':\n",
        "                dims = [float(v) for v in tmp[1].split(',')]\n",
        "                sub_model = TorchModule[name](*dims)\n",
        "\n",
        "            module_list.append(sub_model)\n",
        "\n",
        "        else:\n",
        "            module_list.append(TorchModule[mylayer])\n",
        "\n",
        "    module_list = nn.ModuleList(module_list)\n",
        "    return nn.Sequential(*module_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Gxf2-wu445"
      },
      "source": [
        "# Examples with this module function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIrlxgCE3dIm"
      },
      "outputs": [],
      "source": [
        "# Simple neural network; (B,200) - (B,10) - relu\n",
        "# linear-[in][out]\n",
        "\n",
        "layer_text = 'linear-200,10;relu'\n",
        "model = LayerGroup(layer_text).cuda()\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(10,200).cuda()\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8djIuCxjtvOO"
      },
      "outputs": [],
      "source": [
        "# Neural network; (B,100) - (B,50) - (B,10) - (B,1) (relu as activation function)\n",
        "layer_text = 'your code here'\n",
        "model = LayerGroup(layer_text).cuda()\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(10,100).cuda()\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvpr4nUX3dIm"
      },
      "outputs": [],
      "source": [
        "# Simple convolutional neural network; (B,3,32,32) - (B,32,16,16)\n",
        "# conv2d-[in][out][kernel][stride][padding]\n",
        "\n",
        "layer_text = 'conv2d-3,32,4,2,1;lrelu'\n",
        "model = LayerGroup(layer_text).cuda()\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(10,3,32,32).cuda()\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRFN_4PmtvLT"
      },
      "outputs": [],
      "source": [
        "# Convolution operations; (B,3,32,32) - (B,32,16,16) - (B,64,8,8) - (B,128,4,4) (lrelu as activation function)\n",
        "layer_text = 'your code here'\n",
        "model = LayerGroup(layer_text).cuda()\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(10,3,32,32).cuda()\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz66sz8OtvJF"
      },
      "outputs": [],
      "source": [
        "# Convolution operations; (B,3,32,32) - BatchNorm - (B,32,16,16) - BatchNorm - (B,64,8,8) - BatchNorm - (B,128,4,4) (add lrelu after BatchNorm)\n",
        "# You don't need to write all model information in single line\n",
        "# Define each layer module and then combine it!\n",
        "# bn2d-[dim] ; batch normalization 2D [channel dimension]\n",
        "\n",
        "conv_text1 = 'conv2d-3,32,4,2,1;bn2d-32;lrelu'\n",
        "conv_text2 = 'conv2d-32,64,4,2,1;bn2d-64;lrelu'\n",
        "conv_text3 = 'conv2d-64,128,4,2,1;bn2d-128;lrelu'\n",
        "model = LayerGroup(';'.join([conv_text1,conv_text2,conv_text3])).cuda()\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(10,3,32,32).cuda()\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFg7GYoI0NEY"
      },
      "outputs": [],
      "source": [
        "# Convolution operations; (B,3,32,32) - (B,32,16,16) - (B,64,8,8) - (B,128,4,4) - (B,256,1,1)\n",
        "# Use relu activation function between convolution operations\n",
        "# Apply batch normalization 2D after relu activation function\n",
        "# Use sigmoid function after the last convolution layer\n",
        "\n",
        "conv_text1 = 'your code here'\n",
        "conv_text2 = 'your code here'\n",
        "conv_text3 = 'your code here'\n",
        "conv_text4 = 'your code here'\n",
        "\n",
        "model = LayerGroup(';'.join([conv_text1,conv_text2,conv_text3,conv_text4])).cuda()\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(10,3,32,32).cuda()\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQagA76utvFy"
      },
      "outputs": [],
      "source": [
        "# Combine multiple operations (Convolution -> Fully connected neural network)\n",
        "# Convolution; (B,3,32,32) - (B,32,16,16) - (B,64,8,8) - (B,128,4,4) (add lrelu after BatchNorm)\n",
        "# Each convolution block; convolution 2D -> batch normalization 2D -> lrelu activation\n",
        "# FCNN; (B,128*4*4) - (B,512) - (B,128) - (B,5) (relu between linear layer)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel,self).__init__()\n",
        "\n",
        "        conv_text1 = 'your code here'\n",
        "        conv_text2 = 'your code here'\n",
        "        conv_text3 = 'your code here'\n",
        "        self.conv_block =  LayerGroup(';'.join([conv_text1,conv_text2,conv_text3]))\n",
        "\n",
        "        fc_text = 'your code here'\n",
        "        self.fcnn = LayerGroup(fc_text)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv_block(x)\n",
        "        x = x.view(-1,128*4*4)\n",
        "        x = self.fcnn(x)\n",
        "        return x\n",
        "\n",
        "my_model = MyModel().cuda()\n",
        "print(my_model)\n",
        "\n",
        "x = torch.randn(10,3,32,32).cuda()\n",
        "y = my_model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVFYYRWezNLU"
      },
      "source": [
        "# Example codes on AE, VAE, GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTs7l34l3dIn"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph5veSqYtvCu"
      },
      "outputs": [],
      "source": [
        "# Example for autoencoder with linear layers\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder,self).__init__()\n",
        "\n",
        "        enc_info = 'linear-784,512;relu;linear-512,20'\n",
        "        dec_info = 'linear-20,512;relu;linear-512,784;sigmoid'\n",
        "\n",
        "        self.encoder = LayerGroup(enc_info)\n",
        "        self.decoder = LayerGroup(dec_info)\n",
        "\n",
        "    def forward(self,x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return z,out\n",
        "\n",
        "AE = Autoencoder().cuda()\n",
        "print(AE)\n",
        "\n",
        "x = torch.randn(10,784).cuda()\n",
        "z,x_pred = AE(x)\n",
        "print(x.shape)\n",
        "print(z.shape)\n",
        "print(x_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b2R1HhF3dIn"
      },
      "outputs": [],
      "source": [
        "# Example for autoencoder with linear layers\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,enc_info,dec_info):\n",
        "        super(Autoencoder,self).__init__()\n",
        "\n",
        "        self.encoder = LayerGroup(enc_info)\n",
        "        self.decoder = LayerGroup(dec_info)\n",
        "\n",
        "    def forward(self,x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return z,out\n",
        "\n",
        "enc_info = 'linear-784,512;relu;linear-512,20'\n",
        "dec_info = 'linear-20,512;relu;linear-512,784;sigmoid'\n",
        "\n",
        "AE = Autoencoder(enc_info,dec_info).cuda()\n",
        "print(AE)\n",
        "\n",
        "x = torch.randn(10,784).cuda()\n",
        "z,x_pred = AE(x)\n",
        "print(x.shape)\n",
        "print(z.shape)\n",
        "print(x_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydkRO2JM3dIo"
      },
      "outputs": [],
      "source": [
        "# Example for autoencoder with linear layers\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,dim_x,dim_h,dim_z):\n",
        "        super(Autoencoder,self).__init__()\n",
        "\n",
        "        self.enc_info = f'linear-{dim_x},{dim_h};relu;linear-{dim_h},{dim_z}'\n",
        "        self.dec_info = f'linear-{dim_z},{dim_h};relu;linear-{dim_h},{dim_x};sigmoid'\n",
        "\n",
        "        self.encoder = LayerGroup(self.enc_info)\n",
        "        self.decoder = LayerGroup(self.dec_info)\n",
        "\n",
        "    def forward(self,x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return z,out\n",
        "\n",
        "dim_x = 28*28\n",
        "dim_h = 512\n",
        "dim_z = 64\n",
        "\n",
        "AE = Autoencoder(dim_x,dim_h,dim_z).cuda()\n",
        "print(AE)\n",
        "\n",
        "x = torch.randn(10,784).cuda()\n",
        "z,x_pred = AE(x)\n",
        "print(x.shape)\n",
        "print(z.shape)\n",
        "print(x_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU_CCfljuI63",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Write code for autoencoder training with MNIST dataset\n",
        "\n",
        "# Model construction\n",
        "# Encoder; (B,28*28) - (B,dim_h) - (B,dim_z)\n",
        "# Decoder; (B,dim_z) - (B,dim_h) - (B,28*28)\n",
        "# Use relu activation function between linear layer for both encoder & decoder\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,dim_x,dim_h,dim_z):\n",
        "        super(Autoencoder,self).__init__()\n",
        "\n",
        "        self.enc_info = 'your code here'\n",
        "        self.dec_info = 'your code here'\n",
        "\n",
        "        self.encoder = LayerGroup(self.enc_info)\n",
        "        self.decoder = LayerGroup(self.dec_info)\n",
        "\n",
        "    def forward(self,x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return z,out\n",
        "\n",
        "dim_x = 28*28\n",
        "dim_h = 512\n",
        "dim_z = 64\n",
        "\n",
        "AE = Autoencoder(dim_x,dim_h,dim_z).cuda()\n",
        "\n",
        "# dataset & dataloader construction\n",
        "training_data = datasets.MNIST(root=\"./\",train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.MNIST(root=\"./\",train=False,download=True,transform=ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "#note; shape of img = [1,28,28], shape of target = [1]\n",
        "\n",
        "# training code\n",
        "optimizer = torch.optim.Adam(AE.parameters(), lr=0.001)\n",
        "\n",
        "num_epoch = 10\n",
        "Loss = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    print('============= Epoch: '+str(epoch+1)+' =============')\n",
        "    AE.train()\n",
        "\n",
        "    L1 = 0\n",
        "    N1 = 0\n",
        "    for x,y in tqdm(train_dataloader):\n",
        "        x = x.cuda().view(-1,28*28)\n",
        "\n",
        "        z,x_pred = AE(x)\n",
        "\n",
        "        loss = 'your code here'\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        L1 += len(x)*loss.detach().cpu().numpy()\n",
        "        N1 += len(x)\n",
        "\n",
        "    AE.eval()\n",
        "    Zs = []\n",
        "    Xs = []\n",
        "    Ys = []\n",
        "\n",
        "    L2 = 0\n",
        "    N2 = 0\n",
        "    for x,y in tqdm(test_dataloader):\n",
        "        x = x.cuda().view(-1,28*28)\n",
        "\n",
        "        z,x_pred = AE(x)\n",
        "\n",
        "        loss = 'your code here'\n",
        "\n",
        "        L2 += len(x)*loss.detach().cpu().numpy()\n",
        "        N2 += len(x)\n",
        "\n",
        "        Zs.append(z.detach().cpu().numpy())\n",
        "        Xs.append(x_pred.detach().cpu().numpy())\n",
        "        Ys.append(y.detach().cpu().numpy())\n",
        "\n",
        "    Loss.append([L1/N1,L2/N2])\n",
        "    print(Loss[-1])\n",
        "\n",
        "Loss = np.array(Loss)\n",
        "Zs = np.vstack(Zs)\n",
        "Xs = np.vstack(Xs)\n",
        "Ys = np.hstack(Ys)\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "plt.plot(Loss[:,0],'o--',label='train')\n",
        "plt.plot(Loss[:,1],'o--',label='test')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(Xs[i].reshape(28,28),cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-FtbOog3dIo"
      },
      "source": [
        "# Convolution Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "RIiLB7313dIo"
      },
      "outputs": [],
      "source": [
        "# Write code for convolutional autoencoder training with MNIST dataset\n",
        "\n",
        "# Model construction\n",
        "class ConvAE(nn.Module):\n",
        "    def __init__(self,dim_c,dim_z):\n",
        "        super(ConvAE,self).__init__()\n",
        "        self.dim_z = dim_z\n",
        "\n",
        "        self.enc_info = ['your code here', # [dim_c,14,14]\n",
        "                         'your code here', # [2*dim_c,7,7]\n",
        "                         'your code here'] # [dim_z,1,1]\n",
        "\n",
        "        self.dec_info = ['your code here', # [2*dim_c,7,7]\n",
        "                         'your code here', # [dim_c,14,14]\n",
        "                         'your code here'] # [1,28,28] (add sigmoid function after last conv layer)\n",
        "\n",
        "        self.encoder = LayerGroup(';'.join(self.enc_info))\n",
        "        self.decoder = LayerGroup(';'.join(self.dec_info))\n",
        "\n",
        "    def forward(self,x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return z,out\n",
        "\n",
        "dim_c = 32\n",
        "dim_z = 32\n",
        "\n",
        "AE = ConvAE(dim_c,dim_z).cuda()\n",
        "\n",
        "print(AE)\n",
        "\n",
        "# dataset & dataloader construction\n",
        "training_data = datasets.MNIST(root=\"./\",train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.MNIST(root=\"./\",train=False,download=True,transform=ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "#note; shape of img = [1,28,28], shape of target = [1]\n",
        "\n",
        "# training code\n",
        "optimizer = torch.optim.Adam(AE.parameters(), lr=0.0003)\n",
        "\n",
        "num_epoch = 10\n",
        "Loss = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    print('============= Epoch: '+str(epoch+1)+' =============')\n",
        "    AE.train()\n",
        "\n",
        "    L1 = 0\n",
        "    N1 = 0\n",
        "    for x,y in tqdm(train_dataloader):\n",
        "        x = x.cuda()\n",
        "\n",
        "        z,x_pred = AE(x)\n",
        "\n",
        "        loss = torch.mean((x_pred-x)**2)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        L1 += len(x)*loss.detach().cpu().numpy()\n",
        "        N1 += len(x)\n",
        "\n",
        "    AE.eval()\n",
        "    Zs = []\n",
        "    Xs = []\n",
        "    Ys = []\n",
        "\n",
        "    L2 = 0\n",
        "    N2 = 0\n",
        "    for x,y in tqdm(test_dataloader):\n",
        "        x = x.cuda()\n",
        "\n",
        "        z,x_pred = AE(x)\n",
        "\n",
        "        loss = torch.mean((x_pred-x)**2)\n",
        "\n",
        "        L2 += len(x)*loss.detach().cpu().numpy()\n",
        "        N2 += len(x)\n",
        "\n",
        "        Zs.append(z.detach().cpu().numpy())\n",
        "        Xs.append(x_pred.detach().cpu().numpy())\n",
        "        Ys.append(y.detach().cpu().numpy())\n",
        "\n",
        "    Loss.append([L1/N1,L2/N2])\n",
        "    print(Loss[-1])\n",
        "\n",
        "Loss = np.array(Loss)\n",
        "Zs = np.vstack(Zs)\n",
        "Xs = np.vstack(Xs)\n",
        "Ys = np.hstack(Ys)\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "plt.plot(Loss[:,0],'o--',label='train')\n",
        "plt.plot(Loss[:,1],'o--',label='test')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(Xs[i].reshape(28,28),cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEHLv2xm3dIo"
      },
      "source": [
        "# Variational Autoencoder with CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "vsDR2RZe3dIo"
      },
      "outputs": [],
      "source": [
        "# Write code for convolutional autoencoder training with MNIST dataset\n",
        "\n",
        "# Model construction\n",
        "class ConvVAE(nn.Module):\n",
        "    def __init__(self,dim_c,dim_z):\n",
        "        super(ConvVAE,self).__init__()\n",
        "        self.dim_z = dim_z\n",
        "\n",
        "        self.enc_info = ['your code here', # [dim_c,14,14]\n",
        "                         'your code here', # [2*dim_c,7,7]\n",
        "                         'your code here' # [2*dim_z,1,1]\n",
        "\n",
        "        self.dec_info = ['your code here', # [2*dim_c,7,7]\n",
        "                         'your code here', # [dim_c,14,14]\n",
        "                         'your code here'] # [1,28,28] (add sigmoid function after last conv layer)\n",
        "\n",
        "        self.encoder = LayerGroup(';'.join(self.enc_info))\n",
        "        self.decoder = LayerGroup(';'.join(self.dec_info))\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        nz = self.dim_z\n",
        "        h = self.encoder(x)\n",
        "\n",
        "        mu = h[:,:nz]\n",
        "        logvar = h[:,nz:]\n",
        "\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps*std\n",
        "\n",
        "        out = self.decoder(z)\n",
        "        return z,out,mu,logvar\n",
        "\n",
        "dim_c = 16\n",
        "dim_z = 32\n",
        "\n",
        "AE = ConvVAE(dim_c,dim_z).cuda()\n",
        "\n",
        "print(AE)\n",
        "\n",
        "# dataset & dataloader construction\n",
        "training_data = datasets.MNIST(root=\"./\",train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.MNIST(root=\"./\",train=False,download=True,transform=ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "#note; shape of img = [1,28,28], shape of target = [1]\n",
        "\n",
        "# training code\n",
        "optimizer = torch.optim.Adam(AE.parameters(), lr=0.0003)\n",
        "\n",
        "num_epoch = 10\n",
        "Loss = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    print('============= Epoch: '+str(epoch+1)+' =============')\n",
        "    AE.train()\n",
        "\n",
        "    L1 = 0\n",
        "    N1 = 0\n",
        "    for x,y in tqdm(train_dataloader):\n",
        "        x = x.cuda()\n",
        "\n",
        "        z,x_pred,mu,logvar = AE(x)\n",
        "\n",
        "        rec = 'your code here'\n",
        "        kld = 'your code here'\n",
        "\n",
        "        loss = rec + 0.015*kld\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        L1 += len(x)*rec.detach().cpu().numpy()\n",
        "        N1 += len(x)\n",
        "\n",
        "    AE.eval()\n",
        "    Zs = []\n",
        "    Xs = []\n",
        "    Ys = []\n",
        "\n",
        "    L2 = 0\n",
        "    N2 = 0\n",
        "    for x,y in tqdm(test_dataloader):\n",
        "        x = x.cuda()\n",
        "\n",
        "        z,x_pred,mu,logvar = AE(x)\n",
        "\n",
        "        rec = 'your code here'\n",
        "        kld = 'your code here'\n",
        "\n",
        "        L2 += len(x)*rec.detach().cpu().numpy()\n",
        "        N2 += len(x)\n",
        "\n",
        "        Zs.append(z.detach().cpu().numpy())\n",
        "        Xs.append(x_pred.detach().cpu().numpy())\n",
        "        Ys.append(y.detach().cpu().numpy())\n",
        "\n",
        "    Loss.append([L1/N1,L2/N2])\n",
        "    print(Loss[-1])\n",
        "\n",
        "Loss = np.array(Loss)\n",
        "Zs = np.vstack(Zs).reshape(-1,dim_z)\n",
        "Xs = np.vstack(Xs)\n",
        "Ys = np.hstack(Ys)\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "plt.plot(Loss[:,0],'o--',label='train')\n",
        "plt.plot(Loss[:,1],'o--',label='test')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(Xs[i].reshape(28,28),cmap='gray')\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "for i in range(dim_z):\n",
        "    sns.kdeplot(Zs[:,i])\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "\n",
        "z = torch.randn(16,dim_z,1,1).cuda()\n",
        "x_new = AE.decoder(z).cpu().detach().numpy()\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(x_new[i].reshape(28,28),cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBukpLvT3dIo"
      },
      "source": [
        "# GAN (Convolutions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isZTNHlYOhSX"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, conv_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv_info = [f'conv2d-1,{conv_dim},4,2,1;lrelu',\n",
        "                          f'conv2d-{conv_dim},{conv_dim*2},4,2,1;bn2d-{conv_dim*2};lrelu',\n",
        "                          f'conv2d-{conv_dim*2},{conv_dim*4},4,2,1;bn2d-{conv_dim*4};lrelu',\n",
        "                          f'conv2d-{conv_dim*4},1,4,2,1'] # What is the expected output dimension at each step?\n",
        "\n",
        "        self.conv_layer = LayerGroup(';'.join(self.conv_info))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = len(x)\n",
        "\n",
        "        out = self.conv_layer(x)\n",
        "        return out.view(-1,1)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim, conv_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv_dim = conv_dim\n",
        "\n",
        "        self.convtrans_info = [f'convtrans2d-{z_dim},{conv_dim*8},4,1,0;bn2d-{conv_dim*8};relu',\n",
        "                               f'convtrans2d-{conv_dim*8},{conv_dim*4},4,2,1;bn2d-{conv_dim*4};relu',\n",
        "                               f'convtrans2d-{conv_dim*4},{conv_dim*2},4,2,1;bn2d-{conv_dim*2};relu',\n",
        "                               f'convtrans2d-{conv_dim*2},{conv_dim},4,2,1;bn2d-{conv_dim};relu',\n",
        "                               f'convtrans2d-{conv_dim},1,1,1,2;tanh'] # What is the expected output dimension at each step?\n",
        "\n",
        "        self.convtrans_layer = LayerGroup(';'.join(self.convtrans_info))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = len(x)\n",
        "        x = x.view(B,-1,1,1)\n",
        "        out = self.convtrans_layer(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIcU-7E-21t7"
      },
      "outputs": [],
      "source": [
        "# dataset & dataloader construction\n",
        "training_data = datasets.MNIST(root=\"./\",train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.MNIST(root=\"./\",train=False,download=True,transform=ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "z_dim = 100\n",
        "conv_dim = 64\n",
        "\n",
        "D = Discriminator(conv_dim).cuda()\n",
        "G = Generator(z_dim,conv_dim).cuda()\n",
        "\n",
        "print(D)\n",
        "print(G)\n",
        "\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "\n",
        "optim_D = torch.optim.Adam(D.parameters(),lr=0.0002,betas=[beta1,beta2])\n",
        "optim_G = torch.optim.Adam(G.parameters(),lr=0.0002,betas=[beta1,beta2])\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "num_epoch = 10\n",
        "smooth = True\n",
        "\n",
        "Loss = []\n",
        "D.train()\n",
        "G.train()\n",
        "for epoch in range(num_epoch):\n",
        "    print('============= Epoch: '+str(epoch+1)+' =============')\n",
        "\n",
        "    for batch_i,(real_img,_) in enumerate(train_dataloader):\n",
        "\n",
        "        # ============================================\n",
        "        #            TRAIN THE DISCRIMINATOR\n",
        "        # ============================================\n",
        "\n",
        "        batch_size = real_img.shape[0]\n",
        "\n",
        "        real_img = 2*real_img-1\n",
        "        real_img = real_img.cuda()\n",
        "\n",
        "        optim_D.zero_grad()\n",
        "\n",
        "        D_real = D(real_img)\n",
        "\n",
        "        if smooth:\n",
        "            labels = 0.9*torch.ones(batch_size).cuda()\n",
        "        else:\n",
        "            labels = torch.ones(batch_size).cuda()\n",
        "\n",
        "        loss_real = criterion(D_real.view(-1),labels)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(batch_size,z_dim).cuda()\n",
        "            fake_img = G(z)\n",
        "\n",
        "        D_fake = D(fake_img)\n",
        "        labels = torch.zeros(batch_size).cuda()\n",
        "        loss_fake = criterion(D_fake.view(-1),labels)\n",
        "\n",
        "        loss_D = loss_real + loss_fake\n",
        "        loss_D.backward()\n",
        "        optim_D.step()\n",
        "\n",
        "        # =========================================\n",
        "        #            TRAIN THE GENERATOR\n",
        "        # =========================================\n",
        "\n",
        "        optim_G.zero_grad()\n",
        "\n",
        "        z = torch.randn(batch_size,z_dim).cuda()\n",
        "        fake_img = G(z)\n",
        "\n",
        "        D_fake = D(fake_img)\n",
        "\n",
        "        if smooth:\n",
        "            labels = 0.9*torch.ones(batch_size).cuda()\n",
        "        else:\n",
        "            labels = torch.ones(batch_size).cuda()\n",
        "\n",
        "        loss_G = criterion(D_fake.view(-1),labels)\n",
        "        loss_G.backward()\n",
        "        optim_G.step()\n",
        "\n",
        "        if batch_i % 400 == 0:\n",
        "            # print discriminator and generator loss\n",
        "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "                    epoch+1, num_epoch, loss_D.item(), loss_G.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMNqPYWT3CyP"
      },
      "outputs": [],
      "source": [
        "G.eval()\n",
        "\n",
        "sample_size=16\n",
        "z = torch.randn(sample_size,z_dim).cuda()\n",
        "samples = G(z).cpu().detach().numpy()\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "\n",
        "    img = np.transpose(samples[i],(1,2,0))\n",
        "    img = (img+1)/2\n",
        "\n",
        "    plt.imshow(img,cmap='gray')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}